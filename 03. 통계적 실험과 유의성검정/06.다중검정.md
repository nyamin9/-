# 🎰 06. 다중검정  

🎲 다양한 관점으로 데이터를 보고 여러 질문을 던지다 보면 거의 항상 통계적으로 유의미한 결과가 나오게 됨  

🎲 예를 들어 20개의 예측변수와 1개의 결과변수가 모두 임의로 생성되었을 때 유의수준 0.05에서 20번의 일련의 유의성검정을 수행하면 적어도 하나의 예측변수에서 통계적으로 유의미한 결과를 실수로 초래하는 1종 오류가 일어날 가능성이 존재함  

🎲 20번 모두 무의미하다고 정확하게 검정할 확률이 (0.95)^20 으로 0.36 이므로, 모든 경우 올바은 결과를 만들 확률이 낮음.  

🎲 적어도 하나의 예측값이 유의미하다고 결과가 나올 확률은 1 - 0.36 = 0.64 이므로 꽤나 높은 값을 가지고, 이를 알파 인플레이션이라고 함  
 

🎲 즉, 추가하는 변수가 많을수록 또는 더 많은 모델을 사용할수록 뭔가가 우연에 의해 ‘유의미한’ 것으로 나타날 확률이 커지기 때문에, 이는 오버피팅 문제와도 관련이 있음  

🎲 이를 해소하기 위해서 지도학습에서는 홀드아웃 세트를 사용해 이전에 보지 못했던 데이터를 사용해서 모델을 평가함  

<br>  


🎲 용어 정리  

- 제1종 오류 : 어떤 효과가 통계적으로 유의미하다고 잘못된 결론을 내리는 것  
   
- 거짓 발견 비율 (FDR) : 다중검정에서 1종 오류가 발생하는 비율  
   
- 알파 인플레이션 : 1종 오류를 만들 확률인 알파가 더 많은 테스트를 수행할수록 증가하는 다중검정 현상  
 
- p 값 조정 : 동일한 데이터에 대해 다중검정을 수행하는 경우 필요  
   
- 오버피팅 : 모델이 잡음까지 학습하는 것  
   
<br>  

🎲 검정횟수가 늘어날수록 동일한 유의수준에 대해 알파 인플레이션이 발생할 확률이 커지기 때문에, 이를 위한 수정 절차가 필요함  

🎲 이러한 수정을 위해서, 일반적으로 검정 횟수에 따라 유의수준을 나누는 방법을 사용함  

🎲 그 중 하나인 본페로니 수정에서는 간단히 알파를 비교 횟수 n으로 나눠 통계적 유의성에 대해 엄격한 임계값을 적용함  

🎲 투키의 HSD 테스트는 그룹 평균 간의 최대 차이(모든 값을 섞고 원래 그룹과 동일한 크기의 재표본 그룹을 뽑아 재표본한 그룹 평균 간의 최대 차이)에 적용되며 t 분포를 기반으로 한 벤치마크와 비교하여 수정함  

<br>  

🎲 결론적으로 데이터의 여러 변수를 비교하는 다중비교나 다양한 변수, 많은 모델은 다중성을 가지기 때문에 많은 유의성검정의 횟수가 필요함. 하지만 이때 알파 인플레이션과 같은 문제가 발생할 수 있기 때문에, 유의수준을 수정해서 이를 보완할 수 있는 방법이 필요함  

<br>  

***  



