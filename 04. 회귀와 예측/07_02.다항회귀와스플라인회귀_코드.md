# ğŸ° 07_02. ë‹¤í•­íšŒê·€ì™€ ìŠ¤í”Œë¼ì¸íšŒê·€  

## ğŸ° 07.01. R ì½”ë“œ  

ğŸ² ë‹¤í•­ì‹ : `MODEL <- lm(RESPONSE ~ poly(INDEPENDENT, degree_num) + INDEPENDENT1 + ... + INDEPENDENT_n, data = DATA)`  



```r

## poly() í•¨ìˆ˜
## íšŒê·€ë¶„ì„ ê²°ê³¼ SqFtTotLivingì— ëŒ€í•´ ë‘ ê°€ì§€ ê³„ìˆ˜ê°€ ì¡´ì¬í•¨ -> ì¼ì°¨í•­, ì´ì°¨í•­
## ì‹œê°í™” ê²°ê³¼ ì„ í˜•íšŒê·€ì¼ ë•Œì— ë¹„í•´ í¸ì”ì°¨ì˜ í‰í™œê³¡ì„ ì— ê°€ê¹Œìš´ ê²ƒì„ ë³¼ ìˆ˜ ìˆìŒ
## ë‹¤í•­íšŒê·€ í›„ ê´€ê³„ íŒŒì•…ì„ ìœ„í•´ í¸ì”ì°¨ê·¸ë¦¼ plot

lm_98105_poly <- lm(AdjSalePrice ~ poly(SqFtTotLiving, 2) + SqFtLot + 
                    BldgGrade + Bathrooms + Bedrooms, data = house_98105)

terms_poly <- predict(lm_98105_poly, type = 'terms') # ê°œë³„ íšŒê·€í•­
partial_resid_poly <- resid(lm_98105_poly) + terms_poly # í¸ì”ì°¨ = ì”ì°¨ + íšŒê·€í•­

df_poly <- data.frame(SqFtTotLiving = house_98105[, 'SqFtTotLiving'],
                 Terms = terms_poly[, 'poly(SqFtTotLiving, 2)'],
                 PartialResid = partial_resid_poly[, 'poly(SqFtTotLiving, 2)'])

ggplot(df_poly, aes(SqFtTotLiving, PartialResid)) +
  geom_point(shape = 1) +
  scale_shape(solid = FALSE) +
  geom_smooth(linetype = 2) +
  geom_line(aes(SqFtTotLiving, Terms))
  
```  

![image](https://user-images.githubusercontent.com/65170165/217724899-64f1937e-06a2-4df3-ae22-5967cb321acc.png)  

<br>  

ğŸ² ìŠ¤í”Œë¼ì¸  

`lm_spline <- lm(RESPONSE ~ bs(INDEPENDENT, knots = KNOTS, degree = degree_num) + INDEPENDENT1 + ... + INDEPENDENT_n, data = DATA)`  


```r

## bs() í•¨ìˆ˜
## ë…ë¦½ë³€ìˆ˜ë¥¼ ìœ„í•œ ì„ì˜ì˜ ê³ ì •ëœ ì ì„ ë¶€ë“œëŸ½ê²Œ ì—°ê²°í•¨
## ìŠ¤í”Œë¼ì¸ í•­ì˜ ê³„ìˆ˜ëŠ” í•´ì„ì´ ì–´ë ¤ì›€ -> ì í•©ë„ í™•ì¸ì„ ìœ„í•´ ì‹œê°í™”ë¥¼ ì‹œìš©í•˜ì—¬ ë¶„ì„
## ë‹¤í•­íšŒê·€ë³´ë‹¤ ë§¤ë„ëŸ¬ìš´ ê³¡ì„ 
## ìŠ¤í”Œë¼ì¸ íšŒê·€ í›„ í¸ì”ì°¨ ê·¸ë¦¼ plot

## í•˜ì§€ë§Œ í¬ê¸°ê°€ ì•„ì£¼ ì‘ì€ ì£¼íƒì´ ë³´ë‹¤ í° ì£¼íƒì— ë¹„í•´ ë†’ì€ ê°€ì¹˜ë¥¼ ê°€ì§ˆ ê²ƒì´ë¼ëŠ” íšŒê·€ì„ ì˜ ê²°ê³¼ëŠ” ì˜³ì§€ ì•ŠìŒ

#install.packages("splines") 
library(splines)

# knots ì„¤ì •
knots <- quantile(house_98105$SqFtTotLiving, p = c(0.25, 0.5, 0.75))
lm_spline <- lm(AdjSalePrice ~ bs(SqFtTotLiving, knots = knots, degree = 3) + 
                SqFtLot + Bathrooms + Bedrooms + BldgGrade, data = house_98105)

terms1 <- predict(lm_spline, type='terms')
partial_resid1 <- resid(lm_spline) + terms1

df1 <- data.frame(SqFtTotLiving = house_98105[, 'SqFtTotLiving'],
                  Terms = terms1[, 1],
                  PartialResid = partial_resid1[, 1])

graph <- ggplot(df1, aes(SqFtTotLiving, PartialResid)) +
  geom_point(shape=1) + scale_shape(solid = FALSE) +
  geom_smooth(linetype=2, formula=y~x, method='loess') + 
  geom_line(aes(SqFtTotLiving, Terms)) +
  scale_y_continuous(labels = function(x) format(x, scientific = FALSE))

graph  

```  

![image](https://user-images.githubusercontent.com/65170165/217725432-4551ded6-ce11-430f-a84b-3cda69c1cc54.png)  

<br>  

ğŸ² ì¼ë°˜í™”ê°€ë²•ëª¨í˜•  

`lm_gam <- gam(RESPONSE ~ s(INDEPENDENT) + INDEPENDENT1 + ... + INDEPENDENT_n, data = DATA)`  

              

```r

## ìŠ¤í”Œë¼ì¸ í•­ì€ knotsì˜ ìœ„ì¹˜ë¥¼ ì§€ì •í•´ì¤˜ì•¼ í•˜ì§€ë§Œ GAMì€ ìë™ìœ¼ë¡œ ê·¸ ìœ„ì¹˜ë¥¼ ì¡ì•„ì¤Œ
#install.packages("mgcv")
library(mgcv)

lm_gam <- gam(AdjSalePrice ~ s(SqFtTotLiving) + SqFtLot + Bathrooms + 
              Bedrooms + BldgGrade, data = house_98105)

## GAM íšŒê·€ í›„ í¸ì”ì°¨ ê·¸ë¦¼ plot

terms2 <- predict(lm_gam, type='terms')
partial_resid2 <- resid(lm_gam) + terms2

df2 <- data.frame(SqFtTotLiving = house_98105[, 'SqFtTotLiving'],
                  Terms = terms2[, 5],
                  PartialResid = partial_resid2[, 5])

graph <- ggplot(df2, aes(SqFtTotLiving, PartialResid)) +
  geom_point(shape=1) + scale_shape(solid = FALSE) +
  geom_smooth(linetype=2, formula=y~x, method='loess') + 
  geom_line(aes(SqFtTotLiving, Terms)) +
  scale_y_continuous(labels = function(x) format(x, scientific = FALSE))

graph

```  

![image](https://user-images.githubusercontent.com/65170165/217725870-ee073bf2-5978-45b8-b9e2-8ca876578ab5.png)  

<br>  

***  

## ğŸ° 07.02. python ì½”ë“œ  

```py

## ì‹œê°í™”ë¥¼ ìœ„í•œ í•¨ìˆ˜ ì •ì˜

def partialResidualPlot(model, df, outcome, feature, ax):
    y_pred = model.predict(df)
    copy_df = df.copy()
    for c in copy_df.columns:
        if c == feature:
            continue
        copy_df[c] = 0.0
    feature_prediction = model.predict(copy_df)
    results = pd.DataFrame({
        'feature': df[feature],
        'residual': df[outcome] - y_pred,
        'ypartial': feature_prediction - model.params[0],
    })
    results = results.sort_values(by=['feature'])
    smoothed = sm.nonparametric.lowess(results.ypartial, results.feature, frac=1/3)
    
    ax.scatter(results.feature, results.ypartial + results.residual)
    ax.plot(smoothed[:, 0], smoothed[:, 1], color='gray')
    ax.plot(results.feature, results.ypartial, color='black')
    ax.set_xlabel(feature)
    ax.set_ylabel(f'Residual + {feature} contribution')
    return ax
    
```    

ğŸ² ë‹¤í•­ì‹  

`MODEL = smf.ols(formula = 'RESPONSE ~  INDEPENDENT_1 + np.power(INDEPENDENT_1, degree_num) + ' + 'INDEPENDENT2 + ... + INDEPENDENT_n', data=DATA)`  


```py

import statsmodels.api as sm
import statsmodels.formula.api as smf
from statsmodels.stats.outliers_influence import OLSInfluence

## np.power() -> ì œê³±í•­ ì¶”ê°€
## íšŒê·€ë¶„ì„ ê²°ê³¼ SqFtTotLivingì— ëŒ€í•´ ë‘ ê°€ì§€ ê³„ìˆ˜ê°€ ì¡´ì¬í•¨ -> ì¼ì°¨í•­, ì´ì°¨í•­
## ì‹œê°í™” ê²°ê³¼ ì„ í˜•íšŒê·€ì¼ ë•Œì— ë¹„í•´ í¸ì”ì°¨ì˜ í‰í™œê³¡ì„ ì— ê°€ê¹Œìš´ ê²ƒì„ ë³¼ ìˆ˜ ìˆìŒ

model_poly = smf.ols(formula='AdjSalePrice ~  SqFtTotLiving + np.power(SqFtTotLiving, 2) + ' + 
                'SqFtLot + Bathrooms + Bedrooms + BldgGrade', data=house_98105)
result_poly = model_poly.fit()
print(result_poly.summary())

```   

```
>>

                            OLS Regression Results                            
==============================================================================
Dep. Variable:           AdjSalePrice   R-squared:                       0.806
Model:                            OLS   Adj. R-squared:                  0.802
Method:                 Least Squares   F-statistic:                     211.6
Date:                Mon, 06 Feb 2023   Prob (F-statistic):          9.95e-106
Time:                        01:51:06   Log-Likelihood:                -4217.9
No. Observations:                 313   AIC:                             8450.
Df Residuals:                     306   BIC:                             8476.
Df Model:                           6                                         
Covariance Type:            nonrobust                                         
==============================================================================================
                                 coef    std err          t      P>|t|      [0.025      0.975]
----------------------------------------------------------------------------------------------
Intercept                  -6.159e+05   1.03e+05     -5.953      0.000   -8.19e+05   -4.12e+05
SqFtTotLiving                  7.4521     55.418      0.134      0.893    -101.597     116.501
np.power(SqFtTotLiving, 2)     0.0388      0.010      4.040      0.000       0.020       0.058
SqFtLot                       32.5594      5.436      5.990      0.000      21.863      43.256
Bathrooms                  -1435.1231   1.95e+04     -0.074      0.941   -3.99e+04     3.7e+04
Bedrooms                   -9191.9441   1.33e+04     -0.693      0.489   -3.53e+04    1.69e+04
BldgGrade                   1.357e+05   1.49e+04      9.087      0.000    1.06e+05    1.65e+05
==============================================================================
Omnibus:                       75.161   Durbin-Watson:                   1.625
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              637.978
Skew:                           0.699   Prob(JB):                    2.92e-139
Kurtosis:                       9.853   Cond. No.                     7.37e+07
==============================================================================

```  

<br>  

```py

## ë‹¤í•­íšŒê·€ ê²°ê³¼ ì‹œê°í™”

fig, ax = plt.subplots(figsize=(5, 5))
partialResidualPlot(result_poly, house_98105, 'AdjSalePrice', 'SqFtTotLiving', ax)

plt.tight_layout()
plt.show()

## ì´ì°¨í•­ì˜ íšŒê·€ê³„ìˆ˜ : 0.03879128168237239
print(result_poly.params[2])  

```   

![image](https://user-images.githubusercontent.com/65170165/217726679-e52f4bc1-3b97-4884-a716-48cbe9a93686.png)  

<br>  

ğŸ² ìŠ¤í”Œë¼ì¸ íšŒê·€  

`MODEL = smf.ols(formula = 'RESPONSE ~  bs(INDEPENDENT_1, df=degree_of_free_num, degree_num) + ' + 'INDEPENDENT2 + ... + INDEPENDENT_n', data=DATA)`  


```py

## bs() í•¨ìˆ˜
## ë…ë¦½ë³€ìˆ˜ë¥¼ ìœ„í•œ ì„ì˜ì˜ ê³ ì •ëœ ì ì„ ë¶€ë“œëŸ½ê²Œ ì—°ê²°í•¨
## ìŠ¤í”Œë¼ì¸ í•­ì˜ ê³„ìˆ˜ëŠ” í•´ì„ì´ ì–´ë ¤ì›€ -> ì í•©ë„ í™•ì¸ì„ ìœ„í•´ ì‹œê°í™”ë¥¼ ì‹œìš©í•˜ì—¬ ë¶„ì„
## ë‹¤í•­íšŒê·€ë³´ë‹¤ ë§¤ë„ëŸ¬ìš´ ê³¡ì„ 
## í•˜ì§€ë§Œ í¬ê¸°ê°€ ì•„ì£¼ ì‘ì€ ì£¼íƒì´ ë³´ë‹¤ í° ì£¼íƒì— ë¹„í•´ ë†’ì€ ê°€ì¹˜ë¥¼ ê°€ì§ˆ ê²ƒì´ë¼ëŠ” íšŒê·€ì„ ì˜ ê²°ê³¼ëŠ” ì˜³ì§€ ì•ŠìŒ

formula = ('AdjSalePrice ~ bs(SqFtTotLiving, df=6, degree=3) + ' + 
           'SqFtLot + Bathrooms + Bedrooms + BldgGrade')
           
model_spline = smf.ols(formula=formula, data=house_98105)

result_spline = model_spline.fit()
print(result_spline.summary())

```  

```
>>

                            OLS Regression Results                            
==============================================================================
Dep. Variable:           AdjSalePrice   R-squared:                       0.814
Model:                            OLS   Adj. R-squared:                  0.807
Method:                 Least Squares   F-statistic:                     131.8
Date:                Mon, 06 Feb 2023   Prob (F-statistic):          7.10e-104
Time:                        01:55:08   Log-Likelihood:                -4211.4
No. Observations:                 313   AIC:                             8445.
Df Residuals:                     302   BIC:                             8486.
Df Model:                          10                                         
Covariance Type:            nonrobust                                         
========================================================================================================
                                           coef    std err          t      P>|t|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------
Intercept                            -4.142e+05   1.43e+05     -2.899      0.004   -6.95e+05   -1.33e+05
bs(SqFtTotLiving, df=6, degree=3)[0] -1.995e+05   1.86e+05     -1.076      0.283   -5.65e+05    1.66e+05
bs(SqFtTotLiving, df=6, degree=3)[1] -1.206e+05   1.23e+05     -0.983      0.326   -3.62e+05    1.21e+05
bs(SqFtTotLiving, df=6, degree=3)[2] -7.164e+04   1.36e+05     -0.525      0.600    -3.4e+05    1.97e+05
bs(SqFtTotLiving, df=6, degree=3)[3]  1.957e+05   1.62e+05      1.212      0.227   -1.22e+05    5.14e+05
bs(SqFtTotLiving, df=6, degree=3)[4]  8.452e+05   2.18e+05      3.878      0.000    4.16e+05    1.27e+06
bs(SqFtTotLiving, df=6, degree=3)[5]  6.955e+05   2.14e+05      3.255      0.001    2.75e+05    1.12e+06
SqFtLot                                 33.3258      5.454      6.110      0.000      22.592      44.059
Bathrooms                            -4778.2080   1.94e+04     -0.246      0.806    -4.3e+04    3.34e+04
Bedrooms                             -5778.7045   1.32e+04     -0.437      0.663   -3.18e+04    2.03e+04
BldgGrade                             1.345e+05   1.52e+04      8.842      0.000    1.05e+05    1.64e+05
==============================================================================
Omnibus:                       58.816   Durbin-Watson:                   1.633
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              622.021
Skew:                           0.330   Prob(JB):                    8.51e-136
Kurtosis:                       9.874   Cond. No.                     1.97e+05
==============================================================================

```  

<br>  

```py

## ìŠ¤í”Œë¼ì¸ ì‹œê°í™”

fig, ax = plt.subplots(figsize=(5, 5))
partialResidualPlot(result_spline, house_98105, 'AdjSalePrice', 'SqFtTotLiving', ax)

plt.tight_layout()
plt.show()

```  

![image](https://user-images.githubusercontent.com/65170165/217727253-5c7bdc57-7db4-4c22-911c-b8616b89fe12.png)  

<br>  

ğŸ² ì¼ë°˜í™”ê°€ë²•ëª¨í˜•  

- `gam = LinearGAM(s(0, n_splines=12) + l(1) + l(2) + l(3) + l(4))`  

- `gam.gridsearch(X, y)`  


```py

from pygam import LinearGAM, s, l
from pygam.datasets import wage

## ìŠ¤í”Œë¼ì¸ í•­ì€ knotsì˜ ìœ„ì¹˜ë¥¼ ì§€ì •í•´ì¤˜ì•¼ í•˜ì§€ë§Œ GAMì€ ìë™ìœ¼ë¡œ ê·¸ ìœ„ì¹˜ë¥¼ ì¡ì•„ì¤Œ

predictors = ['SqFtTotLiving', 'SqFtLot', 'Bathrooms', 
              'Bedrooms', 'BldgGrade']
outcome = 'AdjSalePrice'

X = house_98105[predictors].values
y = house_98105[outcome]

## model
gam = LinearGAM(s(0, n_splines=12) + l(1) + l(2) + l(3) + l(4))
gam.gridsearch(X, y)
print(gam.summary())

```  

```
>>

100% (11 of 11) |########################| Elapsed Time: 0:00:00 Time:  0:00:00
LinearGAM                                                                                                 
=============================================== ==========================================================
Distribution:                        NormalDist Effective DoF:                                      7.6772
Link Function:                     IdentityLink Log Likelihood:                                 -7833.1159
Number of Samples:                          313 AIC:                                            15683.5863
                                                AICc:                                             15684.14
                                                GCV:                                      30838885095.1708
                                                Scale:                                    29480381715.8322
                                                Pseudo R-Squared:                                   0.8117
==========================================================================================================
Feature Function                  Lambda               Rank         EDoF         P > x        Sig. Code   
================================= ==================== ============ ============ ============ ============
s(0)                              [15.8489]            12           4.3          1.11e-16     ***         
l(1)                              [15.8489]            1            0.9          2.35e-10     ***         
l(2)                              [15.8489]            1            0.8          8.45e-01                 
l(3)                              [15.8489]            1            0.9          3.79e-01                 
l(4)                              [15.8489]            1            0.8          1.11e-16     ***         
intercept                                              1            0.0          9.14e-01                 
==========================================================================================================
Significance codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

```  

<br>  

```py

## GAM ì‹œê°í™”

fig, axes = plt.subplots(figsize=(8, 8), ncols=2, nrows=3)

titles = ['SqFtTotLiving', 'SqFtLot', 'Bathrooms', 'Bedrooms', 'BldgGrade']

for i, title in enumerate(titles):
    ax = axes[i // 2, i % 2]
    XX = gam.generate_X_grid(term=i)
    ax.plot(XX[:, i], gam.partial_dependence(term=i, X=XX))
    ax.plot(XX[:, i], gam.partial_dependence(term=i, X=XX, width=.95)[1], c='r', ls='--')
    ax.set_title(titles[i]);
    
axes[2][1].set_visible(False)

plt.tight_layout()
plt.show()

```  

![image](https://user-images.githubusercontent.com/65170165/217727930-fa4665ca-b3ae-4cc3-a80e-8edb990867d0.png)  

<br>  

***  

  




 


