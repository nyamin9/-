# 🎰 07_02. 다항회귀와 스플라인회귀  

## 🎰 07.01. R 코드  

🎲 다항식 : `MODEL <- lm(RESPONSE ~ poly(INDEPENDENT, degree_num) + INDEPENDENT1 + ... + INDEPENDENT_n, data = DATA)`  



```r

## poly() 함수
## 회귀분석 결과 SqFtTotLiving에 대해 두 가지 계수가 존재함 -> 일차항, 이차항
## 시각화 결과 선형회귀일 때에 비해 편잔차의 평활곡선에 가까운 것을 볼 수 있음
## 다항회귀 후 관계 파악을 위해 편잔차그림 plot

lm_98105_poly <- lm(AdjSalePrice ~ poly(SqFtTotLiving, 2) + SqFtLot + 
                    BldgGrade + Bathrooms + Bedrooms, data = house_98105)

terms_poly <- predict(lm_98105_poly, type = 'terms') # 개별 회귀항
partial_resid_poly <- resid(lm_98105_poly) + terms_poly # 편잔차 = 잔차 + 회귀항

df_poly <- data.frame(SqFtTotLiving = house_98105[, 'SqFtTotLiving'],
                 Terms = terms_poly[, 'poly(SqFtTotLiving, 2)'],
                 PartialResid = partial_resid_poly[, 'poly(SqFtTotLiving, 2)'])

ggplot(df_poly, aes(SqFtTotLiving, PartialResid)) +
  geom_point(shape = 1) +
  scale_shape(solid = FALSE) +
  geom_smooth(linetype = 2) +
  geom_line(aes(SqFtTotLiving, Terms))
  
```  

![image](https://user-images.githubusercontent.com/65170165/217724899-64f1937e-06a2-4df3-ae22-5967cb321acc.png)  

<br>  

🎲 스플라인  

`lm_spline <- lm(RESPONSE ~ bs(INDEPENDENT, knots = KNOTS, degree = degree_num) + INDEPENDENT1 + ... + INDEPENDENT_n, data = DATA)`  


```r

## bs() 함수
## 독립변수를 위한 임의의 고정된 점을 부드럽게 연결함
## 스플라인 항의 계수는 해석이 어려움 -> 적합도 확인을 위해 시각화를 시용하여 분석
## 다항회귀보다 매끄러운 곡선
## 스플라인 회귀 후 편잔차 그림 plot

## 하지만 크기가 아주 작은 주택이 보다 큰 주택에 비해 높은 가치를 가질 것이라는 회귀선의 결과는 옳지 않음

#install.packages("splines") 
library(splines)

# knots 설정
knots <- quantile(house_98105$SqFtTotLiving, p = c(0.25, 0.5, 0.75))
lm_spline <- lm(AdjSalePrice ~ bs(SqFtTotLiving, knots = knots, degree = 3) + 
                SqFtLot + Bathrooms + Bedrooms + BldgGrade, data = house_98105)

terms1 <- predict(lm_spline, type='terms')
partial_resid1 <- resid(lm_spline) + terms1

df1 <- data.frame(SqFtTotLiving = house_98105[, 'SqFtTotLiving'],
                  Terms = terms1[, 1],
                  PartialResid = partial_resid1[, 1])

graph <- ggplot(df1, aes(SqFtTotLiving, PartialResid)) +
  geom_point(shape=1) + scale_shape(solid = FALSE) +
  geom_smooth(linetype=2, formula=y~x, method='loess') + 
  geom_line(aes(SqFtTotLiving, Terms)) +
  scale_y_continuous(labels = function(x) format(x, scientific = FALSE))

graph  

```  

![image](https://user-images.githubusercontent.com/65170165/217725432-4551ded6-ce11-430f-a84b-3cda69c1cc54.png)  

<br>  

🎲 일반화가법모형  

`lm_gam <- gam(RESPONSE ~ s(INDEPENDENT) + INDEPENDENT1 + ... + INDEPENDENT_n, data = DATA)`  

              

```r

## 스플라인 항은 knots의 위치를 지정해줘야 하지만 GAM은 자동으로 그 위치를 잡아줌
#install.packages("mgcv")
library(mgcv)

lm_gam <- gam(AdjSalePrice ~ s(SqFtTotLiving) + SqFtLot + Bathrooms + 
              Bedrooms + BldgGrade, data = house_98105)

## GAM 회귀 후 편잔차 그림 plot

terms2 <- predict(lm_gam, type='terms')
partial_resid2 <- resid(lm_gam) + terms2

df2 <- data.frame(SqFtTotLiving = house_98105[, 'SqFtTotLiving'],
                  Terms = terms2[, 5],
                  PartialResid = partial_resid2[, 5])

graph <- ggplot(df2, aes(SqFtTotLiving, PartialResid)) +
  geom_point(shape=1) + scale_shape(solid = FALSE) +
  geom_smooth(linetype=2, formula=y~x, method='loess') + 
  geom_line(aes(SqFtTotLiving, Terms)) +
  scale_y_continuous(labels = function(x) format(x, scientific = FALSE))

graph

```  

![image](https://user-images.githubusercontent.com/65170165/217725870-ee073bf2-5978-45b8-b9e2-8ca876578ab5.png)  

<br>  

***  

## 🎰 07.02. python 코드  

```py

## 시각화를 위한 함수 정의

def partialResidualPlot(model, df, outcome, feature, ax):
    y_pred = model.predict(df)
    copy_df = df.copy()
    for c in copy_df.columns:
        if c == feature:
            continue
        copy_df[c] = 0.0
    feature_prediction = model.predict(copy_df)
    results = pd.DataFrame({
        'feature': df[feature],
        'residual': df[outcome] - y_pred,
        'ypartial': feature_prediction - model.params[0],
    })
    results = results.sort_values(by=['feature'])
    smoothed = sm.nonparametric.lowess(results.ypartial, results.feature, frac=1/3)
    
    ax.scatter(results.feature, results.ypartial + results.residual)
    ax.plot(smoothed[:, 0], smoothed[:, 1], color='gray')
    ax.plot(results.feature, results.ypartial, color='black')
    ax.set_xlabel(feature)
    ax.set_ylabel(f'Residual + {feature} contribution')
    return ax
    
```    

🎲 다항식  

`MODEL = smf.ols(formula = 'RESPONSE ~  INDEPENDENT_1 + np.power(INDEPENDENT_1, degree_num) + ' + 'INDEPENDENT2 + ... + INDEPENDENT_n', data=DATA)`  


```py

import statsmodels.api as sm
import statsmodels.formula.api as smf
from statsmodels.stats.outliers_influence import OLSInfluence

## np.power() -> 제곱항 추가
## 회귀분석 결과 SqFtTotLiving에 대해 두 가지 계수가 존재함 -> 일차항, 이차항
## 시각화 결과 선형회귀일 때에 비해 편잔차의 평활곡선에 가까운 것을 볼 수 있음

model_poly = smf.ols(formula='AdjSalePrice ~  SqFtTotLiving + np.power(SqFtTotLiving, 2) + ' + 
                'SqFtLot + Bathrooms + Bedrooms + BldgGrade', data=house_98105)
result_poly = model_poly.fit()
print(result_poly.summary())

```   

```
>>

                            OLS Regression Results                            
==============================================================================
Dep. Variable:           AdjSalePrice   R-squared:                       0.806
Model:                            OLS   Adj. R-squared:                  0.802
Method:                 Least Squares   F-statistic:                     211.6
Date:                Mon, 06 Feb 2023   Prob (F-statistic):          9.95e-106
Time:                        01:51:06   Log-Likelihood:                -4217.9
No. Observations:                 313   AIC:                             8450.
Df Residuals:                     306   BIC:                             8476.
Df Model:                           6                                         
Covariance Type:            nonrobust                                         
==============================================================================================
                                 coef    std err          t      P>|t|      [0.025      0.975]
----------------------------------------------------------------------------------------------
Intercept                  -6.159e+05   1.03e+05     -5.953      0.000   -8.19e+05   -4.12e+05
SqFtTotLiving                  7.4521     55.418      0.134      0.893    -101.597     116.501
np.power(SqFtTotLiving, 2)     0.0388      0.010      4.040      0.000       0.020       0.058
SqFtLot                       32.5594      5.436      5.990      0.000      21.863      43.256
Bathrooms                  -1435.1231   1.95e+04     -0.074      0.941   -3.99e+04     3.7e+04
Bedrooms                   -9191.9441   1.33e+04     -0.693      0.489   -3.53e+04    1.69e+04
BldgGrade                   1.357e+05   1.49e+04      9.087      0.000    1.06e+05    1.65e+05
==============================================================================
Omnibus:                       75.161   Durbin-Watson:                   1.625
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              637.978
Skew:                           0.699   Prob(JB):                    2.92e-139
Kurtosis:                       9.853   Cond. No.                     7.37e+07
==============================================================================

```  

<br>  

```py

## 다항회귀 결과 시각화

fig, ax = plt.subplots(figsize=(5, 5))
partialResidualPlot(result_poly, house_98105, 'AdjSalePrice', 'SqFtTotLiving', ax)

plt.tight_layout()
plt.show()

## 이차항의 회귀계수 : 0.03879128168237239
print(result_poly.params[2])  

```   

![image](https://user-images.githubusercontent.com/65170165/217726679-e52f4bc1-3b97-4884-a716-48cbe9a93686.png)  

<br>  

🎲 스플라인 회귀  

`MODEL = smf.ols(formula = 'RESPONSE ~  bs(INDEPENDENT_1, df=degree_of_free_num, degree_num) + ' + 'INDEPENDENT2 + ... + INDEPENDENT_n', data=DATA)`  


```py

## bs() 함수
## 독립변수를 위한 임의의 고정된 점을 부드럽게 연결함
## 스플라인 항의 계수는 해석이 어려움 -> 적합도 확인을 위해 시각화를 시용하여 분석
## 다항회귀보다 매끄러운 곡선
## 하지만 크기가 아주 작은 주택이 보다 큰 주택에 비해 높은 가치를 가질 것이라는 회귀선의 결과는 옳지 않음

formula = ('AdjSalePrice ~ bs(SqFtTotLiving, df=6, degree=3) + ' + 
           'SqFtLot + Bathrooms + Bedrooms + BldgGrade')
           
model_spline = smf.ols(formula=formula, data=house_98105)

result_spline = model_spline.fit()
print(result_spline.summary())

```  

```
>>

                            OLS Regression Results                            
==============================================================================
Dep. Variable:           AdjSalePrice   R-squared:                       0.814
Model:                            OLS   Adj. R-squared:                  0.807
Method:                 Least Squares   F-statistic:                     131.8
Date:                Mon, 06 Feb 2023   Prob (F-statistic):          7.10e-104
Time:                        01:55:08   Log-Likelihood:                -4211.4
No. Observations:                 313   AIC:                             8445.
Df Residuals:                     302   BIC:                             8486.
Df Model:                          10                                         
Covariance Type:            nonrobust                                         
========================================================================================================
                                           coef    std err          t      P>|t|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------
Intercept                            -4.142e+05   1.43e+05     -2.899      0.004   -6.95e+05   -1.33e+05
bs(SqFtTotLiving, df=6, degree=3)[0] -1.995e+05   1.86e+05     -1.076      0.283   -5.65e+05    1.66e+05
bs(SqFtTotLiving, df=6, degree=3)[1] -1.206e+05   1.23e+05     -0.983      0.326   -3.62e+05    1.21e+05
bs(SqFtTotLiving, df=6, degree=3)[2] -7.164e+04   1.36e+05     -0.525      0.600    -3.4e+05    1.97e+05
bs(SqFtTotLiving, df=6, degree=3)[3]  1.957e+05   1.62e+05      1.212      0.227   -1.22e+05    5.14e+05
bs(SqFtTotLiving, df=6, degree=3)[4]  8.452e+05   2.18e+05      3.878      0.000    4.16e+05    1.27e+06
bs(SqFtTotLiving, df=6, degree=3)[5]  6.955e+05   2.14e+05      3.255      0.001    2.75e+05    1.12e+06
SqFtLot                                 33.3258      5.454      6.110      0.000      22.592      44.059
Bathrooms                            -4778.2080   1.94e+04     -0.246      0.806    -4.3e+04    3.34e+04
Bedrooms                             -5778.7045   1.32e+04     -0.437      0.663   -3.18e+04    2.03e+04
BldgGrade                             1.345e+05   1.52e+04      8.842      0.000    1.05e+05    1.64e+05
==============================================================================
Omnibus:                       58.816   Durbin-Watson:                   1.633
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              622.021
Skew:                           0.330   Prob(JB):                    8.51e-136
Kurtosis:                       9.874   Cond. No.                     1.97e+05
==============================================================================

```  

<br>  

```py

## 스플라인 시각화

fig, ax = plt.subplots(figsize=(5, 5))
partialResidualPlot(result_spline, house_98105, 'AdjSalePrice', 'SqFtTotLiving', ax)

plt.tight_layout()
plt.show()

```  

![image](https://user-images.githubusercontent.com/65170165/217727253-5c7bdc57-7db4-4c22-911c-b8616b89fe12.png)  

<br>  

🎲 일반화가법모형  

- `gam = LinearGAM(s(0, n_splines=12) + l(1) + l(2) + l(3) + l(4))`  

- `gam.gridsearch(X, y)`  


```py

from pygam import LinearGAM, s, l
from pygam.datasets import wage

## 스플라인 항은 knots의 위치를 지정해줘야 하지만 GAM은 자동으로 그 위치를 잡아줌

predictors = ['SqFtTotLiving', 'SqFtLot', 'Bathrooms', 
              'Bedrooms', 'BldgGrade']
outcome = 'AdjSalePrice'

X = house_98105[predictors].values
y = house_98105[outcome]

## model
gam = LinearGAM(s(0, n_splines=12) + l(1) + l(2) + l(3) + l(4))
gam.gridsearch(X, y)
print(gam.summary())

```  

```
>>

100% (11 of 11) |########################| Elapsed Time: 0:00:00 Time:  0:00:00
LinearGAM                                                                                                 
=============================================== ==========================================================
Distribution:                        NormalDist Effective DoF:                                      7.6772
Link Function:                     IdentityLink Log Likelihood:                                 -7833.1159
Number of Samples:                          313 AIC:                                            15683.5863
                                                AICc:                                             15684.14
                                                GCV:                                      30838885095.1708
                                                Scale:                                    29480381715.8322
                                                Pseudo R-Squared:                                   0.8117
==========================================================================================================
Feature Function                  Lambda               Rank         EDoF         P > x        Sig. Code   
================================= ==================== ============ ============ ============ ============
s(0)                              [15.8489]            12           4.3          1.11e-16     ***         
l(1)                              [15.8489]            1            0.9          2.35e-10     ***         
l(2)                              [15.8489]            1            0.8          8.45e-01                 
l(3)                              [15.8489]            1            0.9          3.79e-01                 
l(4)                              [15.8489]            1            0.8          1.11e-16     ***         
intercept                                              1            0.0          9.14e-01                 
==========================================================================================================
Significance codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

```  

<br>  

```py

## GAM 시각화

fig, axes = plt.subplots(figsize=(8, 8), ncols=2, nrows=3)

titles = ['SqFtTotLiving', 'SqFtLot', 'Bathrooms', 'Bedrooms', 'BldgGrade']

for i, title in enumerate(titles):
    ax = axes[i // 2, i % 2]
    XX = gam.generate_X_grid(term=i)
    ax.plot(XX[:, i], gam.partial_dependence(term=i, X=XX))
    ax.plot(XX[:, i], gam.partial_dependence(term=i, X=XX, width=.95)[1], c='r', ls='--')
    ax.set_title(titles[i]);
    
axes[2][1].set_visible(False)

plt.tight_layout()
plt.show()

```  

![image](https://user-images.githubusercontent.com/65170165/217727930-fa4665ca-b3ae-4cc3-a80e-8edb990867d0.png)  

<br>  

***  

  




 


